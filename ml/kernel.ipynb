{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# organize imports\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "config={\n",
    "  \"model\"           : \"inceptionv3\",\n",
    "  \"weights\"         : \"imagenet\",\n",
    "  \"include_top\"     : False,\n",
    "  \"features_path\"   : \"features.h5\",\n",
    "  \"labels_path\"     : \"labels.h5\",\n",
    "  \"results\"         : \"output/IOdev/inceptionv3/results.txt\",\n",
    "  \"classifier_path\" : \"output/IOdev/inceptionv3/classifier/\",\n",
    "  \"model_path\"      : \"output/IOdev/inceptionv3/model\",\n",
    "\n",
    "  \"test_size\"       : 0.15,\n",
    "  \"seed\"            : 9,\n",
    "  \"num_classes\"     : 14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "385e663657556a982897751b7d14c78afe072418"
   },
   "outputs": [],
   "source": [
    "# config variables\n",
    "test_size     = config[\"test_size\"]\n",
    "seed      = config[\"seed\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "results     = config[\"results\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "train_path    = ['Effusion', 'Atelectasis', 'Edema', 'Hernia', 'Mass', 'Nodule', 'Fibrosis', 'Emphysema', 'Cardiomegaly', 'Consolidation', 'Infiltration', 'Pneumonia', 'Pneumothorax', 'Pleural_Thickening']\n",
    "num_classes   = config[\"num_classes\"]\n",
    "classifier_path = config[\"classifier_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "53781602357a6d3a15161defde145dfde0c53f93"
   },
   "outputs": [],
   "source": [
    "# import features and labels\n",
    "h5f_data  = h5py.File(features_path, 'r')\n",
    "h5f_label = h5py.File(labels_path, 'r')\n",
    "\n",
    "features_string = h5f_data['dataset_1']\n",
    "labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_string)\n",
    "labels   = np.array(labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "aec7ac7d60782fca7d95c5dc5d60659e7d56f8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (8881, 131072)\n",
      "[INFO] labels shape: (8881,)\n"
     ]
    }
   ],
   "source": [
    "del features_string,labels_string,h5f_data,h5f_label\n",
    "gc.collect()\n",
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(features.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "15b1e3a92770051ecac861bd492e5eb0c5e69c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training started...\n",
      "[INFO] splitted train and test data...\n",
      "[INFO] train data  : (7548, 131072)\n",
      "[INFO] test data   : (1333, 131072)\n",
      "[INFO] train labels: (7548,)\n",
      "[INFO] test labels : (1333,)\n"
     ]
    }
   ],
   "source": [
    "print (\"[INFO] training started...\")\n",
    "# split the training and testing data\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(labels),\n",
    "                                                                  test_size=test_size,\n",
    "                                                                  random_state=seed)\n",
    "\n",
    "print (\"[INFO] splitted train and test data...\")\n",
    "print (\"[INFO] train data  : {}\".format(trainData.shape))\n",
    "print (\"[INFO] test data   : {}\".format(testData.shape))\n",
    "print (\"[INFO] train labels: {}\".format(trainLabels.shape))\n",
    "print (\"[INFO] test labels : {}\".format(testLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5f5f04e1c4870a1a9d8dcc1e262d8ab9b92d4ff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del features,labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3c6ba88b245c9730bb89ec03f6ec22bf522b223b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 3198.24, NNZs: 131060, Bias: -13.023785, T: 7548, Avg. loss: 1808.216445\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5947.59, NNZs: 131072, Bias: -12.101671, T: 7548, Avg. loss: 10513.898498\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5861.85, NNZs: 131072, Bias: -15.092058, T: 7548, Avg. loss: 9677.652677\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5657.56, NNZs: 131072, Bias: -12.443821, T: 7548, Avg. loss: 7942.834771\n",
      "Total training time: 2.37 seconds.\n",
      "Norm: 5907.73, NNZs: 131071, Bias: -52.384216, T: 7548, Avg. loss: 8685.866229Norm: 5816.58, NNZs: 131072, Bias: -15.486104, T: 7548, Avg. loss: 7993.488322\n",
      "Total training time: 2.36 seconds.\n",
      "\n",
      "-- Epoch 2\n",
      "-- Epoch 2\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5963.04, NNZs: 131072, Bias: -17.913313, T: 7548, Avg. loss: 8850.212640\n",
      "Total training time: 2.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5683.02, NNZs: 131072, Bias: -5.484776, T: 7548, Avg. loss: 8812.653356\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2315.77, NNZs: 131067, Bias: -12.498553, T: 15096, Avg. loss: 316.620392\n",
      "Total training time: 4.17 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4238.47, NNZs: 131072, Bias: -17.464676, T: 15096, Avg. loss: 1357.951075\n",
      "Total training time: 4.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4393.68, NNZs: 131072, Bias: -14.667809, T: 15096, Avg. loss: 1761.737447\n",
      "Total training time: 4.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4593.49, NNZs: 131072, Bias: -15.135903, T: 15096, Avg. loss: 2068.813814\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4163.69, NNZs: 131072, Bias: -9.664269, T: 15096, Avg. loss: 1535.563481\n",
      "Total training time: 4.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4331.15, NNZs: 131072, Bias: -50.785701, T: 15096, Avg. loss: 1852.641368\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4310.19, NNZs: 131072, Bias: -20.413187, T: 15096, Avg. loss: 1583.218288\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4326.30, NNZs: 131072, Bias: -4.902938, T: 15096, Avg. loss: 1637.592018\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1891.59, NNZs: 131070, Bias: -13.551462, T: 22644, Avg. loss: 120.443433\n",
      "Total training time: 6.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3421.48, NNZs: 131072, Bias: -17.445565, T: 22644, Avg. loss: 532.940698\n",
      "Total training time: 6.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3609.02, NNZs: 131072, Bias: -15.464712, T: 22644, Avg. loss: 740.241987\n",
      "Total training time: 6.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3794.44, NNZs: 131072, Bias: -16.449429, T: 22644, Avg. loss: 809.543205\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3341.00, NNZs: 131072, Bias: -9.368155, T: 22644, Avg. loss: 606.076538\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3604.07, NNZs: 131072, Bias: -21.105065, T: 22644, Avg. loss: 665.400182\n",
      "Total training time: 6.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3540.24, NNZs: 131072, Bias: -52.307611, T: 22644, Avg. loss: 745.429732\n",
      "Total training time: 7.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3547.89, NNZs: 131072, Bias: -5.045620, T: 22644, Avg. loss: 749.880651\n",
      "Total training time: 7.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1549.20, NNZs: 131070, Bias: -13.558008, T: 30192, Avg. loss: 37.317650\n",
      "Total training time: 8.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2911.13, NNZs: 131072, Bias: -17.834974, T: 30192, Avg. loss: 280.418960\n",
      "Total training time: 9.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3083.81, NNZs: 131072, Bias: -15.822721, T: 30192, Avg. loss: 386.380559\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3226.57, NNZs: 131072, Bias: -16.709271, T: 30192, Avg. loss: 387.897222\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2857.40, NNZs: 131072, Bias: -8.992934, T: 30192, Avg. loss: 276.955454\n",
      "Total training time: 9.21 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3063.23, NNZs: 131072, Bias: -20.309494, T: 30192, Avg. loss: 322.878377\n",
      "Total training time: 9.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2998.84, NNZs: 131072, Bias: -52.349840, T: 30192, Avg. loss: 355.458210\n",
      "Total training time: 9.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3030.13, NNZs: 131072, Bias: -5.712381, T: 30192, Avg. loss: 328.843753\n",
      "Total training time: 9.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1297.21, NNZs: 131070, Bias: -13.556083, T: 37740, Avg. loss: 14.225596\n",
      "Total training time: 10.48 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2529.90, NNZs: 131072, Bias: -18.067240, T: 37740, Avg. loss: 139.761012\n",
      "Total training time: 11.25 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2728.08, NNZs: 131072, Bias: -15.791037, T: 37740, Avg. loss: 199.120912\n",
      "Total training time: 11.38 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2860.94, NNZs: 131072, Bias: -16.364872, T: 37740, Avg. loss: 240.471781\n",
      "Total training time: 11.39 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2684.04, NNZs: 131072, Bias: -20.091740, T: 37740, Avg. loss: 166.573452\n",
      "Total training time: 11.43 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2510.03, NNZs: 131072, Bias: -8.989158, T: 37740, Avg. loss: 178.519359\n",
      "Total training time: 11.44 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 2664.60, NNZs: 131072, Bias: -52.917924, T: 37740, Avg. loss: 224.841129\n",
      "Total training time: 11.67 seconds.\n",
      "Norm: 2634.06, NNZs: 131072, Bias: -4.865293, T: 37740, Avg. loss: 161.171187\n",
      "Total training time: 11.83 seconds.\n",
      "Norm: 5437.28, NNZs: 131072, Bias: 11.479568, T: 7548, Avg. loss: 8406.976161\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5909.59, NNZs: 131072, Bias: -22.897283, T: 7548, Avg. loss: 9470.228432\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4517.60, NNZs: 131072, Bias: -19.774027, T: 7548, Avg. loss: 5260.725552\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5851.10, NNZs: 131072, Bias: -28.126772, T: 7548, Avg. loss: 10449.739548\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5646.44, NNZs: 131072, Bias: -25.540278, T: 7548, Avg. loss: 10204.578013\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5889.38, NNZs: 131072, Bias: -17.287748, T: 7548, Avg. loss: 9737.810897\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4130.93, NNZs: 131072, Bias: 10.542848, T: 15096, Avg. loss: 1551.535337\n",
      "Total training time: 4.16 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3422.20, NNZs: 131072, Bias: -19.231080, T: 15096, Avg. loss: 935.822153\n",
      "Total training time: 3.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4459.98, NNZs: 131072, Bias: -23.006062, T: 15096, Avg. loss: 2106.162765\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4355.04, NNZs: 131072, Bias: -28.359800, T: 15096, Avg. loss: 2183.211725\n",
      "Total training time: 4.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4446.45, NNZs: 131072, Bias: -26.663827, T: 15096, Avg. loss: 2263.174346\n",
      "Total training time: 4.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4396.76, NNZs: 131072, Bias: -18.254636, T: 15096, Avg. loss: 1693.768162\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3359.49, NNZs: 131072, Bias: 11.174359, T: 22644, Avg. loss: 568.762623\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2805.17, NNZs: 131072, Bias: -19.138460, T: 22644, Avg. loss: 338.170187\n",
      "Total training time: 5.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3683.73, NNZs: 131072, Bias: -22.137988, T: 22644, Avg. loss: 866.811392\n",
      "Total training time: 5.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3662.14, NNZs: 131072, Bias: -27.387103, T: 22644, Avg. loss: 965.679635\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2863.37, NNZs: 131072, Bias: 10.759884, T: 30192, Avg. loss: 324.244837\n",
      "Total training time: 7.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3720.61, NNZs: 131072, Bias: -27.176933, T: 22644, Avg. loss: 923.467087\n",
      "Total training time: 6.39 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3625.88, NNZs: 131072, Bias: -19.313497, T: 22644, Avg. loss: 714.436725\n",
      "Total training time: 6.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3198.90, NNZs: 131072, Bias: -21.523258, T: 30192, Avg. loss: 461.619265\n",
      "Total training time: 7.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2394.14, NNZs: 131072, Bias: -19.057825, T: 30192, Avg. loss: 173.319635\n",
      "Total training time: 7.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2495.54, NNZs: 131072, Bias: 10.791698, T: 37740, Avg. loss: 129.029052\n",
      "Total training time: 8.76 seconds.\n",
      "Norm: 3118.47, NNZs: 131072, Bias: -19.069493, T: 30192, Avg. loss: 373.494992\n",
      "Total training time: 8.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3199.57, NNZs: 131072, Bias: -27.830045, T: 30192, Avg. loss: 416.044889\n",
      "Total training time: 8.46 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3197.01, NNZs: 131072, Bias: -27.040126, T: 30192, Avg. loss: 525.564094\n",
      "Total training time: 8.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2809.38, NNZs: 131072, Bias: -22.409449, T: 37740, Avg. loss: 207.849669\n",
      "Total training time: 9.26 seconds.\n",
      "Norm: 2070.68, NNZs: 131072, Bias: -19.073210, T: 37740, Avg. loss: 88.817527\n",
      "Total training time: 9.14 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2701.08, NNZs: 131072, Bias: -19.729956, T: 37740, Avg. loss: 194.958120\n",
      "Total training time: 9.61 seconds.\n",
      "Norm: 2819.38, NNZs: 131072, Bias: -27.408032, T: 37740, Avg. loss: 260.609521\n",
      "Total training time: 10.53 seconds.\n",
      "Norm: 2808.95, NNZs: 131072, Bias: -27.654042, T: 37740, Avg. loss: 254.717173\n",
      "Total training time: 10.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   22.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=9, shuffle=True,\n",
       "       tol=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print (\"[INFO] creating model...\")\n",
    "SGD = SGDClassifier(random_state=seed,verbose=1,n_jobs=-1)\n",
    "SGD.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "0aa54fa3e58bd9af503cce21b66c1ad23b6faa42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 33.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='multinomial',\n",
       "          n_jobs=-1, penalty='l2', random_state=9, solver='lbfgs',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print (\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed,verbose=1,solver='lbfgs',n_jobs=-1,multi_class='multinomial',max_iter=2000,penalty='l2')\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "a762f3692b95227a657bf59039754ae0d0defde1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print (\"[INFO] creating model...\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "85fcb254e1c862129bfdff1240280d28e54dcae2"
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# SVC = LinearSVC(random_state=seed,verbose=1)\n",
    "# SVC.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "f834928c50bc4f455dd9ae35d081120c5bf4a922"
   },
   "outputs": [],
   "source": [
    "# os.mkdir(\"output\")\n",
    "# os.mkdir(\"output/IOdev\")\n",
    "# os.mkdir(\"output/IOdev/inceptionv3/classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9435aa005d9c2974c69c65c6c3a2bda25c338d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating model...\n"
     ]
    }
   ],
   "source": [
    "# use rank-1 and rank-5 predictions\n",
    "print (\"[INFO] evaluating model...\")\n",
    "f = open(results, \"w\")\n",
    "rank_1 = 0\n",
    "rank_5 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "4ffedbb94530fbce6fbf9cd7664a3335a6f67acc"
   },
   "outputs": [],
   "source": [
    "# evaluate the model of test data\n",
    "preds_gnb = gnb.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sgd = SGD.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_LogisticReg=model.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "5d71b3dde66d40563694b1b69daa6dab03e32858"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0edf4026eab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write the classification report to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_gnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_sgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_LogisticReg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# write the classification report to file\n",
    "f.write(\"{}\\n\".format(classification_report(testLabels, preds_gnb)))\n",
    "f.write(\"{}\\n\".format(classification_report(testLabels, preds_sgd)))\n",
    "f.write(\"{}\\n\".format(classification_report(testLabels, preds_LogisticReg)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "0e3bf08ab8170cc1bd0159052dd840152080b2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "# dump classifier to file\n",
    "print (\"[INFO] saving model...\")\n",
    "pickle.dump(model, open(classifier_path+\"classifier_LogisticReg.pickle\", 'wb'))\n",
    "pickle.dump(gnb, open(classifier_path+\"classifier_GNB.pickle\", 'wb'))\n",
    "pickle.dump(SGD, open(classifier_path+\"classifier_SGD.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59964973e4b8deb583bb817a5e5c4c76ea3ccce0"
   },
   "outputs": [],
   "source": [
    "#  display the confusion matrix\n",
    "print (\"[INFO] confusion matrix\")\n",
    "\n",
    "# get the list of training lables\n",
    "labels = sorted(list(train_path))\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(testLabels, preds)\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            cmap=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "cb0a56ff3e39fcb28f2779e0b8172b2bae037c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n",
      "accuracy in Gnb is  22.13053263315829\n"
     ]
    }
   ],
   "source": [
    "total=len(testLabels.tolist())\n",
    "print(total)\n",
    "counter=0\n",
    "for i in range(len(testLabels)):\n",
    "    if testLabels[i]==preds_gnb[i]:\n",
    "        counter+=1\n",
    "print(\"accuracy in Gnb is \",((counter/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n",
      "accuracy in sgd is  19.72993248312078\n"
     ]
    }
   ],
   "source": [
    "total=len(testLabels.tolist())\n",
    "print(total)\n",
    "counter=0\n",
    "for i in range(len(testLabels)):\n",
    "    if testLabels[i]==preds_sgd[i]:\n",
    "        counter+=1\n",
    "print(\"accuracy in sgd is \",((counter/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "bfeae077af4b481a59f04822bb8ff5fdbe1ab17e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n",
      "accuracy in LogisticReg is  27.906976744186046\n"
     ]
    }
   ],
   "source": [
    "total=len(testLabels.tolist())\n",
    "print(total)\n",
    "counter=0\n",
    "for i in range(len(testLabels)):\n",
    "    if testLabels[i]==preds_LogisticReg[i]:\n",
    "        counter+=1\n",
    "print(\"accuracy in LogisticReg is \",((counter/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
